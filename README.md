# ğŸ™ AI-Based Speech to Personality Analysis 


## ğŸš€ Theme

AI for Impact â€“ Open Innovation



>
> A privacy-preserving, multi-agent AI system that evaluates communication skills, confidence, and personality using Agentic AI & RAG.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Architecture: Agentic](https://img.shields.io/badge/Architecture-Agentic%20AI-orange)](https://langchain-ai.github.io/langgraph/)
[![Privacy: Local](https://img.shields.io/badge/Privacy-100%25%20Local-green)](https://ollama.com/)

---

## ğŸ“Œ Executive Summary
VocalPersona is an intelligent speech analysis platform built for the AI for Impact initiative. It helps students, job seekers, and professionals overcome communication barriers by providing objective, psychological-based feedback on their speech delivery.

Unlike standard tools that only analyze text, VocalPersona uses multi-modal agents to "hear" tone, pitch, and pausesâ€”running entirely on local, open-source models to guarantee user privacy.


## â— Problem Statement

In todayâ€™s competitive academic and professional environment, effective communication skills are as important as technical knowledge. However, a large number of students, job seekers, and professionals struggle with expressing themselves clearly and confidently while speaking.

Some of the major challenges include:

- Lack of awareness about how their voice sounds to others  
- Difficulty identifying nervousness, hesitation, or low confidence in speech  
- Poor emotional expression and unclear tone during interviews or presentations  
- Fear of public speaking due to absence of constructive feedback  
- Limited access to personalized communication coaching  

Most existing solutions focus only on what is being said (content) and not how it is being said (delivery, tone, emotion, confidence). Human feedback is often subjective, inconsistent, or not easily accessible to everyone.

There is currently no simple, affordable, and scalable AI-based solution that can:
- Analyze speech objectively  
- Extract personality and communication traits  
- Provide instant, personalized improvement suggestions  

This communication gap directly impacts employability, confidence, and professional growth, especially for students and early-career professionals.


## ğŸ’¡ The Solution: Agentic AI & RAG

VocalPersona solves this by orchestrating a team of specialized AI agents. We don't just ask one LLM to "analyze this." Instead, we treat speech analysis as a workflow:

1.  The Audio Engineer (Librosa): Extracts raw acoustic data (pitch variance, energy, pauses).
2.  The Psychologist (RAG Agent): Retrieves validated rules from a vector database (e.g., "Frequent pauses + low pitch variation = Perceived hesitation").
3.  The Coach (Guardrails): Ensures feedback is constructive and ethical, never medical.

---

## ğŸš€ Key Technical Innovations (Why We Win)

### 1. Multi-Agent Orchestration (LangGraph)
Instead of a single prompt, we use a *Cyclic Graph. Agents pass data to each other. If the *Communication Agent detects a long pause, it triggers the Emotion Agent to check if it was a "thoughtful pause" or a "nervous freeze."

### 2. RAG-Grounded Insights (Zero Hallucination)
We strictly prevent the AI from making up psychology.
* Bad AI: "You sound like a Leo." âŒ
* VocalPersona: "Based on Psychology Today (2018), your rapid speech rate (160wpm) suggests high extraversion." âœ…

### 3. Ethical Guardrails
We use Guardrails AI to filter outputs. The system strictly refuses to diagnose mental health conditions (e.g., anxiety, depression) and focuses solely on behavioral communication improvements.

---

## ğŸ›  Technology Stack

| Domain | Tech | Purpose |
| :--- | :--- | :--- |
| Orchestration | LangGraph, LangChain | Managing the multi-agent state workflow |
| LLMs (Local) | Ollama (Llama-3, Mistral) | Private, on-device reasoning |
| Audio Processing | OpenAI Whisper, Librosa | Transcribing text & extracting acoustic features |
| Vector DB | FAISS, Sentence-Transformers | Storing psychology rules for RAG |
| Backend | FastAPI, Pydantic | High-performance API |
| Quality Control | DeepEval, Guardrails AI | Testing for hallucinations and safety |

---

## ğŸ“‚ Project Structure

```bash
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # FastAPI Entry Point
â”‚   â””â”€â”€ api/                 # Endpoints (Upload/Analyze)
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ workflow.py          # LangGraph Node Definitions
â”‚   â”œâ”€â”€ communication.py     # Fluency Analysis Logic
â”‚   â””â”€â”€ emotion.py           # Acoustic Feature Extraction
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ vector_store/        # FAISS Index (Psychology Rules)
â”‚   â””â”€â”€ ingestion.py         # PDF/Text Loader for Knowledge Base
â”œâ”€â”€ guardrails/
â”‚   â”œâ”€â”€ safety.xml           # Safety rules (No Medical Diagnosis)
â”‚   â””â”€â”€ validator.py         # Output sanitizer
â””â”€â”€ tests/
    â””â”€â”€ evals.py             # DeepEval Metric Tests





---

## ğŸ‘¥ Team Members

- ğŸ§‘â€ğŸ’» [*Praneeth*](https://github.com/gsmpraneeth)  
- ğŸ§‘â€ğŸ’» [*Yaswanth*](https://github.com/Yash14325)  
- ğŸ§‘â€ğŸ’» [*Mahesh*](https://github.com/kolli-mahesh)  
- ğŸ§‘â€ğŸ’» [*Dinesh*](https://github.com/dinesh9997)

---
